# -*- coding: utf-8 -*-
"""Regression model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zVHLREXB-X64dpu2KERKXyf6VX18vYaq
"""

!pip install xgboost --upgrade

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
import xgboost as xgb

# Load the dataset
data = pd.read_csv('/content/drive/MyDrive/data set/claims_data.csv')

# Inspect the data
print(data.head())
print(data.describe());
print("missing values:", data.isnull().sum())
print(data.info())

plt.figure(figsize=(12, 6))
plt.hist(data['loss'], bins=100)
plt.title('Distribution of Loss')
plt.xlabel('Loss Amount')
plt.ylabel('Frequency')
plt.xlim(0, 120000)
plt.show()

# Check skewness
print("skew value: ")
print(data['loss'].skew())

# Log transformation
data['log_loss'] = np.log1p(data['loss'])
data

# Determine which categorical values cannot be converted to boolean data
categorical = [x for x in data.columns if set(pd.unique(data[x])) != {'A', 'B'} and 'cat' in x]
categorical

for col in [
    'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79',
    'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86',
    'cat87', 'cat88', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93',
    'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100',
    'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106',
    'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112',
    'cat113', 'cat114', 'cat115', 'cat116'
]:
    print(f"Unique values in {col}: {data[col].unique()}")

# One-hot encoding function
def process_cat(data, cat_features):
    for cat in cat_features:
        # Check if the column exists in the DataFrame before processing
        if cat in data.columns:  # This line added for check
            # One-hot encode the categorical feature
            data_cat = pd.get_dummies(data[cat], prefix=cat)

            # Join the new one-hot encoded columns with the original data
            data = data.join(data_cat)

            # Drop the original categorical columns
            data.drop(columns=cat, inplace=True)
        else:
            print(f"Column '{cat}' not found in DataFrame, skipping.") # Print if column not found

    return data

data = process_cat(data, categorical)

# Convert other categorical data into boolean data
for i in range(1, 73):
    data['cat' + str(i)] = data['cat' + str(i)].replace({'A': True, 'B': False})

data

# Remove 'id' as itâ€™s not a useful feature for the model, and 'loss' is the target variable
X = data.drop(columns=['id', 'loss'])
y = data['loss']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Output the shapes of the training and test sets
print("Training set shape:", X_train.shape, y_train.shape)
print("Test set shape:", X_test.shape, y_test.shape)

# Check for non-numeric columns
categorical_columns = data.select_dtypes(include=['object', 'category']).columns

# Display remaining categorical columns
print("Remaining categorical columns:", categorical_columns)

# check unique values in each categorical column
for col in categorical_columns:
    unique_values = data[col].unique()
    print(f"Unique values in {col}: {unique_values}")

# Prepare data for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Set the parameters
params = {
    'objective': 'reg:squarederror',  # Use squared error for regression
    'learning_rate': 0.1,
    'random_state': 42
}

# Train the XGBoost
model = xgb.train(
    params,
    dtrain,
    num_boost_round=20000,  # Large number of trees
    evals=[(dtest, 'test')],
    early_stopping_rounds=50,
    verbose_eval=True
)

# Predict on the test set
y_pred = model.predict(dtest)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"Test RMSE: {rmse:.4f}")

# Perform cross-validation
cv_results = xgb.cv(
    params,
    dtrain,
    num_boost_round=20000,
    nfold=5,
    early_stopping_rounds=50,
    metrics="rmse",
    seed=42
)

print(f"Cross-Validation RMSE: {cv_results['test-rmse-mean'].min():.4f}")

# Visualizing Actual vs Predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Diagonal line
plt.title('Actual vs. Predicted')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.grid(True)
plt.show()

# Grid Search for hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0]
}

grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                           param_grid=param_grid,
                           scoring='neg_root_mean_squared_error',
                           cv=3,
                           verbose=1,
                           n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best parameters and model evaluation
print("Best Parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

# Evaluate the best model
y_pred_best = best_model.predict(X_test)
test_rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))
print(f"Test RMSE (Best Model): {test_rmse_best}")